{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GreatKingdom 7x7 Human vs AI (Colab)\n",
        "\n",
        "Text-based play (no GUI). Run cells top to bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9320e57",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo: c:\\Users\\sangmin\\Desktop\\python_projects\\1.Active\\GreatKingdom_zero\n"
          ]
        }
      ],
      "source": [
        "# --- Repo path ---\n",
        "# Colab: set to the cloned repo path, e.g. /content/GreatKingdom_zero\n",
        "# Local: leave empty to auto-detect repo root from cwd.\n",
        "REPO_DIR = ''\n",
        "\n",
        "import os, sys\n",
        "cwd = os.getcwd()\n",
        "repo = REPO_DIR if REPO_DIR else cwd\n",
        "if os.path.basename(repo).lower() == 'notebooks':\n",
        "    repo = os.path.dirname(repo)\n",
        "\n",
        "if not os.path.isdir(repo):\n",
        "    raise FileNotFoundError(f'Repo not found at: {repo}')\n",
        "\n",
        "if repo not in sys.path:\n",
        "    sys.path.insert(0, repo)\n",
        "REPO = repo\n",
        "print('Repo:', REPO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b229cec2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Dependencies ---\n",
        "import importlib.util, subprocess, sys\n",
        "\n",
        "def _ensure(pkg):\n",
        "    if importlib.util.find_spec(pkg) is None:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "\n",
        "_ensure('numpy')\n",
        "_ensure('scipy')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e36b68a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "Checkpoint: c:\\Users\\sangmin\\Desktop\\python_projects\\1.Active\\GreatKingdom_zero\\checkpoints\\board_7\\center_wall_on\\alphazero_best.pt\n"
          ]
        }
      ],
      "source": [
        "# --- Parameters ---\n",
        "import os\n",
        "BOARD_SIZE = 7\n",
        "CENTER_WALL = True\n",
        "KOMI = 3  # choose 3 or 4\n",
        "N_SIM = 100  # MCTS simulations per move\n",
        "HUMAN_COLOR = 'black'  # 'black' or 'white'\n",
        "\n",
        "# Model features (7x7 profile defaults)\n",
        "USE_LIBERTY_FEATURES = True\n",
        "LIBERTY_BINS = 1\n",
        "USE_LAST_MOVES = False\n",
        "\n",
        "C_PUCT = 2.0\n",
        "DIRICHLET_ALPHA = 0.3\n",
        "DIRICHLET_EPSILON = 0.25\n",
        "\n",
        "CKPT_PATH = os.path.join(REPO, 'checkpoints', 'board_7', 'center_wall_on', 'alphazero_best.pt')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', DEVICE)\n",
        "print('Checkpoint:', CKPT_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d0f69d0",
      "metadata": {},
      "outputs": [
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(CKPT_PATH):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCheckpoint not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCKPT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCKPT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m state_dict = ckpt[\u001b[33m'\u001b[39m\u001b[33mnetwork\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Infer num_res_blocks and num_channels from checkpoint\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sangmin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1529\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1521\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1522\u001b[39m                     opened_zipfile,\n\u001b[32m   1523\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1526\u001b[39m                     **pickle_load_args,\n\u001b[32m   1527\u001b[39m                 )\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1531\u001b[39m             opened_zipfile,\n\u001b[32m   1532\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1535\u001b[39m             **pickle_load_args,\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
            "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "# --- Load model and create MCTS ---\n",
        "from env.env import GreatKingdomEnv\n",
        "from network import AlphaZeroNetwork\n",
        "from mcts_alphazero import AlphaZeroMCTS\n",
        "from game_result import winner_label_from_step\n",
        "\n",
        "env = GreatKingdomEnv(board_size=BOARD_SIZE, center_wall=CENTER_WALL, komi=KOMI)\n",
        "\n",
        "import os\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    raise FileNotFoundError(f'Checkpoint not found: {CKPT_PATH}')\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=False)\n",
        "state_dict = ckpt['network']\n",
        "\n",
        "# Infer num_res_blocks and num_channels from checkpoint\n",
        "policy_w = state_dict.get('policy_conv.weight')\n",
        "num_channels = int(policy_w.shape[1]) if policy_w is not None else 64\n",
        "res_blocks = [k for k in state_dict.keys() if k.startswith('res_blocks.') and k.endswith('.conv1.weight')]\n",
        "num_res_blocks = len(res_blocks) if res_blocks else 3\n",
        "\n",
        "net = AlphaZeroNetwork(\n",
        "    board_size=BOARD_SIZE,\n",
        "    num_res_blocks=num_res_blocks,\n",
        "    num_channels=num_channels,\n",
        "    use_liberty_features=USE_LIBERTY_FEATURES,\n",
        "    liberty_bins=LIBERTY_BINS,\n",
        "    use_last_moves=USE_LAST_MOVES\n",
        ").to(DEVICE)\n",
        "\n",
        "net.load_state_dict(state_dict)\n",
        "net.eval()\n",
        "\n",
        "mcts = AlphaZeroMCTS(\n",
        "    net, env,\n",
        "    num_simulations=N_SIM,\n",
        "    c_puct=C_PUCT,\n",
        "    dirichlet_alpha=DIRICHLET_ALPHA,\n",
        "    dirichlet_epsilon=DIRICHLET_EPSILON,\n",
        "    eval_batch_size=1,\n",
        "    use_liberty_features=USE_LIBERTY_FEATURES,\n",
        "    liberty_bins=LIBERTY_BINS,\n",
        "    use_last_moves=USE_LAST_MOVES\n",
        ")\n",
        "\n",
        "print('Model:', num_res_blocks, 'res blocks |', num_channels, 'channels')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb5e67f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Simple ASCII renderer ---\n",
        "def render_ascii(env):\n",
        "    symbols = {0: '.', 1: 'B', 2: 'W', 3: '#'}\n",
        "    header = '  ' + ' '.join(chr(ord('A') + i) for i in range(env.board_size))\n",
        "    print(header)\n",
        "    for r in range(env.board_size):\n",
        "        row = ' '.join(symbols[int(v)] for v in env.board[r])\n",
        "        print(f'{r+1} {row}')\n",
        "    print('Turn:', 'Black' if env.current_player == 1 else 'White')\n",
        "    scores = env.get_territory_scores()\n",
        "    print(f\"Territory - Black: {scores['black']}, White: {scores['white']}\")\n",
        "    print('-' * 20)\n",
        "\n",
        "def parse_move(text, board_size):\n",
        "    text = text.strip().lower()\n",
        "    if text in ('p', 'pass'):\n",
        "        return board_size * board_size\n",
        "\n",
        "    # A1-style: e.g., a1, d5\n",
        "    if len(text) >= 2 and text[0].isalpha():\n",
        "        col = ord(text[0]) - ord('a')\n",
        "        try:\n",
        "            row = int(text[1:]) - 1\n",
        "        except ValueError:\n",
        "            return None\n",
        "        if 0 <= row < board_size and 0 <= col < board_size:\n",
        "            return row * board_size + col\n",
        "        return None\n",
        "\n",
        "    # Space-separated: r c\n",
        "    parts = text.split()\n",
        "    if len(parts) != 2:\n",
        "        return None\n",
        "    try:\n",
        "        r = int(parts[0])\n",
        "        c = int(parts[1])\n",
        "    except ValueError:\n",
        "        return None\n",
        "    if r < 0 or c < 0 or r >= board_size or c >= board_size:\n",
        "        return None\n",
        "    return r * board_size + c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Game loop ---\n",
        "env.reset()\n",
        "last_moves = (None, None) if USE_LAST_MOVES else None\n",
        "human_player = 1 if HUMAN_COLOR == 'black' else 2\n",
        "\n",
        "while True:\n",
        "    render_ascii(env)\n",
        "\n",
        "    if env.current_player == human_player:\n",
        "        legal = env.get_legal_moves()\n",
        "        move = None\n",
        "        while move is None:\n",
        "            raw = input('Your move (r c / a1 / pass): ')\n",
        "            action = parse_move(raw, env.board_size)\n",
        "            if action is None:\n",
        "                print('Invalid input. Example: 2 3 or a1 or pass')\n",
        "                continue\n",
        "            if not legal[action]:\n",
        "                print('Illegal move. Try again.')\n",
        "                continue\n",
        "            move = action\n",
        "        action = move\n",
        "    else:\n",
        "        if USE_LAST_MOVES:\n",
        "            state = (env.board.copy(), env.current_player, env.consecutive_passes, last_moves)\n",
        "        else:\n",
        "            state = (env.board.copy(), env.current_player, env.consecutive_passes)\n",
        "        action, _ = mcts.run(state, temperature=0.0, add_root_noise=False)\n",
        "        print('AI move:', 'pass' if action == env.pass_action else divmod(action, env.board_size))\n",
        "\n",
        "    _, reward, done, info = env.step(action)\n",
        "    if USE_LAST_MOVES and action != env.pass_action:\n",
        "        last_moves = (action, last_moves[0])\n",
        "\n",
        "    if done:\n",
        "        render_ascii(env)\n",
        "        winner = winner_label_from_step(info, reward, env.current_player)\n",
        "        print('Game Over:', info.get('result', ''), '| Winner:', winner)\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}